    # Au dÃ©but du job
    - name: Notify Start
      run: |
        python scripts/discord_notify.py "${{ secrets.DISCORD_WEBHOOK }}" "start" "CI Pipeline started for ${{ github.repository }}"
    
    # Ã€ la fin, aprÃ¨s les tests
    - name: Notify Success
      if: success()
      run: |
        python scripts/discord_notify.py "${{ secrets.DISCORD_WEBHOOK }}" "success" "âœ… All tests passed for ${{ github.repository }}"
    
    - name: Notify Failure
      if: failure()
      run: |
        python scripts/discord_notify.py "${{ secrets.DISCORD_WEBHOOK }}" "failure" "âŒ Tests failed for ${{ github.repository }}"

      name: CI Pipeline

      on:
        push:
         branches: [ main, develop ]
         pull_request:
        branches: [ main ]

        jobs:
        quality-checks:
         runs-on: ubuntu-latest
    
      steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-json-report pylint django-nose axe-selenium-python
    
    - name: Run linter
      run: |
        pylint tasks/ --exit-zero --output-format=json:pylint_report.json
    
    - name: Run Django tests
      run: |
        python manage.py test --noinput --verbosity=2 --testrunner=django_nose.runner.NoseTestSuiteRunner
        python -m pytest tasks/tests/ --json-report --json-report-file=django_report.json
      env:
        DJANGO_SETTINGS_MODULE: todo.settings
    
    - name: Run Selenium tests
      run: |
        python manage.py test tasks.tests.selenium_tests --pattern=*.py --noinput
        # Tes tests Selenium doivent gÃ©nÃ©rer result_test_selenium.json
      env:
        DJANGO_SETTINGS_MODULE: todo.settings
    
    - name: Run accessibility tests
      run: |
        python run_accessibility_tests.py
      env:
        DJANGO_SETTINGS_MODULE: todo.settings
    
    - name: Generate test report
      run: |
        python generate_test_report.py
    
    - name: Upload test reports
      uses: actions/upload-artifact@v3
      with:
        name: test-reports
        path: |
          *.json
          test_summary.txt
    
        - name: Generate PDF Certificate
      if: github.event_name == 'pull_request'
      run: |
        python generate_pdf_report.py
    
    - name: Upload PDF Certificate
      if: github.event_name == 'pull_request'
      uses: actions/upload-artifact@v3
      with:
        name: delivery-certificate
        path: test_certificate_*.pdf
    
    - name: Comment PR with PDF
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const pdfFiles = fs.readdirSync('.').filter(f => f.startsWith('test_certificate_'));
          
          if (pdfFiles.length > 0) {
            const pdfFile = pdfFiles[0];
            const comment = `
            ## ğŸ“„ Delivery Certificate Generated
            
            A PDF certificate has been generated with all test results.
            
            **Certificate includes:**
            - âœ… All test execution results
            - ğŸ“Š Test statistics and metrics
            - ğŸ• Timestamp of execution
            - ğŸ” Quality assurance validation
            
            Download the certificate from the workflow artifacts.
            
            **Next Steps:**
            1. Review the test results
            2. Check for any manual test requirements
            3. Approve and merge if all checks pass
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }


    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          let summary = '## Test Results Summary\\n\\n';
          
          try {
            const data = fs.readFileSync('test_summary.txt', 'utf8');
            summary += data + '\\n\\n';
          } catch (e) {
            summary += 'No test summary found\\n';
          }
          
          summary += '### Manual Tests Remaining\\n';
          summary += '- [ ] Cross-browser testing (Chrome, Firefox)\\n';
          summary += '- [ ] Mobile responsiveness\\n';
          summary += '- [ ] Performance under load\\n';
          summary += '- [ ] Security penetration testing\\n';
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });